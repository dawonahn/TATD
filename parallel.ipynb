{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7efc4381d1f0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from tatd.utils import *\n",
    "from tatd.read import *\n",
    "from tatd.tatd import *\n",
    "\n",
    "import argparse\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.manual_seed(1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "import torch.optim as optim\n",
    "\n",
    "import torch.distributed as dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "from joblib import Parallel, delayed\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "name, sparse, rank, window, penalty, opt_scheme, lr, gpu, count = 'radar', 1, 10, 7, 0.1, 'als_adam', 0.01, 2, 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_path, model_path, total_path  = get_path(name, sparse, rank, window,  penalty,\n",
    "                                              opt_scheme, lr, count)\n",
    "device = f'cuda:{gpu}'\n",
    "\n",
    "dataset = read_dataset(name, device)\n",
    "dataset['count'], dataset['window'] = count, window\n",
    "nmode, ndim, tmode =  dataset['nmode'], dataset['ndim'], dataset['tmode']\n",
    "\n",
    "density = dataset['ts_beta']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "START radar sparse : True & als_adam : 0.01 Rank : 10 Window : 7 Penalty : 0.1 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = Tatd(nmode, ndim, tmode, density, rank, window, sparse, device).to(device)\n",
    "\n",
    "print(f\"START {name} sparse : {bool(sparse)} & {opt_scheme} : {lr} \"\n",
    "      f\"Rank : {rank} Window : {window} Penalty : {penalty} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metadata(train):\n",
    "    indices = train.indices().cpu().numpy()\n",
    "    vals = train.values().cpu().numpy()\n",
    "    temp = np.vstack([indices, vals]).T\n",
    "\n",
    "    dct = {}\n",
    "    dct1 = {}\n",
    "\n",
    "    for mode, index in enumerate(indices):\n",
    "        old_c = 0\n",
    "        dct[mode] = {}\n",
    "        dct1[mode] = {}\n",
    "        unique, indices, counts = np.unique(index, return_index = True, return_counts=True)\n",
    "        for a, c, b in zip(* [unique, indices[1:], counts]):\n",
    "            dct[mode][a] = b\n",
    "            dct1[mode][a] = {}\n",
    "            dct1[mode][a]['idx'] = {}\n",
    "            dct1[mode][a]['value'] = {}\n",
    "            nnz_entries = temp[old_c:c]\n",
    "            old_c = c\n",
    "            nnz_idxs = nnz_entries[:, :-1]\n",
    "            nnz_vals = nnz_entries[:, -1]\n",
    "            dct1[mode][a]['idx'] = nnz_idxs\n",
    "            dct1[mode][a]['val'] = nnz_vals\n",
    "#          'indoor_1', 'indoor_3', 'indoor_5', 'indoor_9',\n",
    "#          'beijing_1', 'beijing_3', 'beijing_5', 'beijing_7',\n",
    "#          'radar_1', 'radar_3', 'radar_5', 'radar_7', 'radar_9',\n",
    "#          'mair_1', 'mair_3', 'mair_5',  'mair_7','mair_9']\n",
    "​\n",
    "name = 'ncfd'\n",
    "file = f'../{path}/als_adam/{name}/best.txt'\n",
    "df = pd.read_csv(file, sep = '\\t')\n",
    "df['Name'] = name\n",
    "total = pd.DataFrame()\n",
    "for name in names:\n",
    "    if name.startswith('mair'):\n",
    "        file = f'../{path}/als_adam2/{name}/best.txt'\n",
    "    else:\n",
    "        file = f'../{path}/als_adam/{name}/best.txt'\n",
    "    df = pd.read_csv(file, sep = '\\t')\n",
    "    df['Name'] = name\n",
    "    total = total.append(df)\n",
    "total = total.reset_index(drop = True)\n",
    "total.columns = ['Count', 'Iters', 'Time', 'Sparse', 'Rank', 'Window', 'Penalty', 'Scheme',\n",
    "       'Lr', 'RMSE', 'MAE', 'Name']\n",
    "total = total.dropna()\n",
    "total = total[['Count', 'Iters', 'Sparse', 'Rank', 'Window', 'Penalty',\n",
    "       'Scheme', 'Lr', 'RMSE', 'MAE', 'Name']]\n",
    "​\n",
    "total['Model'] = 'kernel'\n",
    "total['model_file'] = total.apply(lambda row: f'../{path}/{row.Scheme}/{row.Name}/model/'\n",
    "                                    f'{row.Sparse}_r_{row.Rank}_w_{row.Window}_'\n",
    "                                    f'p_{float(row.Penalty)}_'\n",
    "                                    f'lr_{float(row.Lr)}_'\n",
    "                                    f'{row.Count}-{row.Iters}.pth.tar', axis=1)\n",
    "​\n",
    "total.loc[total['Name'] == 'mair_std', 'model_file', ] = total.apply(lambda row: f'../{path}/als_adam2/{row.Name}/model/'\n",
    "                                    f'{row.Sparse}_r_{row.Rank}_w_{row.Window}_'\n",
    "                                    f'p_{float(row.Penalty)}_'\n",
    "                                    f'lr_{float(row.Lr)}_'\n",
    "                                    f'{row.Count}-{row.Iters}.pth.tar', axis=1)\n",
    "​\n",
    "for i in [1, 3, 5, 7, 9]:\n",
    "    total.loc[total['Name'] == f'mair_{i}', 'model_file', ] = total.apply(lambda row: f'../{path}/als_adam2/{row.Name}/model/'\n",
    "                                    f'{row.Sparse}_r_{row.Rank}_w_{row.Window}_'\n",
    "                                    f'p_{float(row.Penalty)}_'\n",
    "                                    f'lr_{float(row.Lr)}_'\n",
    "                                    f'{row.Count}-{row.Iters}.pth.tar', axis=1)\n",
    "​\n",
    "### HPC\n",
    "# df = pd.read_csv('hpc.txt', sep = '\\t',)\n",
    "# df1 = pd.read_csv('new_hpc2.txt', sep = '\\t',)\n",
    "# df = df.append(df1)\n",
    "​\n",
    "df = pd.read_csv('uber_hpc.txt', sep = '\\t',)\n",
    "df['Sparse'] = 0\n",
    "df['Lr'] = 0\n",
    "df['Window'] = 0\n",
    "df.columns = ['Name', 'Rank', 'Penalty', 'Count', 'RMSE', 'MAE', 'model_file', 'Scheme',\n",
    "       'Model', 'Sparse', 'Lr', 'Window']\n",
    "​\n",
    "df.loc[lambda df: df['Name'] == 'energy1', 'Name'] = 'indoor'\n",
    "df.loc[lambda df: df['Name'] == 'energy_1', 'Name'] = 'indoor_1'\n",
    "df.loc[lambda df: df['Name'] == 'energy_3', 'Name'] = 'indoor_3'\n",
    "df.loc[lambda df: df['Name'] == 'energy_5', 'Name'] = 'indoor_5'\n",
    "df.loc[lambda df: df['Name'] == 'energy_9', 'Name'] = 'indoor_9'\n",
    "​\n",
    "​\n",
    "total = total.append(df)\n",
    "​\n",
    "total = total.reset_index(drop = True)\n",
    "​\n",
    "total.to_csv('./data_ver1.txt', sep = '\\t', header = True, index = False)\n",
    "section 1 : Table\n",
    "​\n",
    "bdf = total[[ 'Model', 'Name', 'RMSE','MAE', 'Rank', 'Sparse' ]]\n",
    "​\n",
    "header = pd.MultiIndex.from_product([['beijing',  'mad', 'energy1', 'radar'],\n",
    "                                     ['RMSE', 'MAE']],\n",
    "                                    names=['Data', 'Metric'])\n",
    "index = pd.MultiIndex.from_product([['kernel']],\n",
    "                                    names=['Model'])\n",
    "# index = pd.MultiIndex.from_product([['kernel', 'attention_dot']],\n",
    "#                                     names=['Model'])\n",
    "​\n",
    "# index = pd.MultiIndex.from_product([['kernel', 'attention_dot', 'standard']],\n",
    "#                                     names=['Model'])\n",
    "​\n",
    "​\n",
    "​\n",
    "​\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Code\n",
    "\n",
    "Python 3\n",
    "​\n",
    "from tatd.utils import *\n",
    "from tatd.read import *\n",
    "from tatd.tatd import *\n",
    "​\n",
    "import argparse\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.manual_seed(1234)\n",
    "<torch._C.Generator at 0x7efc4381d1f0>\n",
    "import time\n",
    "​\n",
    "import torch.optim as optim\n",
    "​\n",
    "import torch.distributed as dist\n",
    "import multiprocessing\n",
    "from joblib import Parallel, delayed\n",
    "from tqdm import tqdm\n",
    "radar\n",
    "name, sparse, rank, window, penalty, opt_scheme, lr, gpu, count = 'radar', 1, 10, 7, 0.1, 'als_adam', 0.01, 2, 10\n",
    "loss_path, model_path, total_path  = get_path(name, sparse, rank, window,  penalty,\n",
    "                                              opt_scheme, lr, count)\n",
    "device = f'cuda:{gpu}'\n",
    "​\n",
    "dataset = read_dataset(name, device)\n",
    "dataset['count'], dataset['window'] = count, window\n",
    "nmode, ndim, tmode =  dataset['nmode'], dataset['ndim'], dataset['tmode']\n",
    "​\n",
    "density = dataset['ts_beta']\n",
    "model = Tatd(nmode, ndim, tmode, density, rank, window, sparse, device).to(device)\n",
    "​\n",
    "print(f\"START {name} sparse : {bool(sparse)} & {opt_scheme} : {lr} \"\n",
    "      f\"Rank : {rank} Window : {window} Penalty : {penalty} \\n\")\n",
    "START radar sparse : True & als_adam : 0.01 Rank : 10 Window : 7 Penalty : 0.1 \n",
    "\n",
    "def metadata(train):\n",
    "    indices = train.indices().cpu().numpy()\n",
    "    vals = train.values().cpu().numpy()\n",
    "    temp = np.vstack([indices, vals]).T\n",
    "​\n",
    "    dct = {}\n",
    "    dct1 = {}\n",
    "​\n",
    "    for mode, index in enumerate(indices):\n",
    "        old_c = 0\n",
    "        dct[mode] = {}\n",
    "        dct1[mode] = {}\n",
    "        unique, indices, counts = np.unique(index, return_index = True, return_counts=True)\n",
    "        for a, c, b in zip(* [unique, indices[1:], counts]):\n",
    "            dct[mode][a] = b\n",
    "            dct1[mode][a] = {}\n",
    "            dct1[mode][a]['idx'] = {}\n",
    "            dct1[mode][a]['value'] = {}\n",
    "            nnz_entries = temp[old_c:c]\n",
    "            old_c = c\n",
    "            nnz_idxs = nnz_entries[:, :-1]\n",
    "            nnz_vals = nnz_entries[:, -1]\n",
    "            dct1[mode][a]['idx'] = nnz_idxs\n",
    "            dct1[mode][a]['val'] = nnz_vals\n",
    "    return dct, dct1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, valid, test = dataset['train'], dataset['valid'], dataset['test']\n",
    "nmode, tmode = dataset['nmode'], dataset['tmode']\n",
    "window, count = dataset['window'], dataset['count']\n",
    "\n",
    "dct, temp = metadata(train)\n",
    "opt = optim.Adam([list(model.parameters())[tmode]], lr = lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/999 [00:00<?, ?it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "ones(): argument 'size' must be tuple of ints, but found element of type dict at pos 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31m_RemoteTraceback\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;31m_RemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"/home/dawon/.local/lib/python3.6/site-packages/joblib/externals/loky/process_executor.py\", line 418, in _process_worker\n    r = call_item()\n  File \"/home/dawon/.local/lib/python3.6/site-packages/joblib/externals/loky/process_executor.py\", line 272, in __call__\n    return self.fn(*self.args, **self.kwargs)\n  File \"/home/dawon/.local/lib/python3.6/site-packages/joblib/_parallel_backends.py\", line 608, in __call__\n    return self.func(*args, **kwargs)\n  File \"/home/dawon/.local/lib/python3.6/site-packages/joblib/parallel.py\", line 256, in __call__\n    for func, args, kwargs in self.items]\n  File \"/home/dawon/.local/lib/python3.6/site-packages/joblib/parallel.py\", line 256, in <listcomp>\n    for func, args, kwargs in self.items]\n  File \"<ipython-input-44-cd28373d3400>\", line 8, in row_wise\n  File \"<ipython-input-45-9feff0d657d7>\", line 2, in sub_function\nTypeError: ones(): argument 'size' must be tuple of ints, but found element of type dict at pos 1\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-46-027aca29300b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m als_train_model(dataset, model, penalty, opt_scheme, lr, rank, device,\n\u001b[0;32m----> 2\u001b[0;31m                     loss_path, model_path, total_path)\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-40-fd4a0c4f8781>\u001b[0m in \u001b[0;36mals_train_model\u001b[0;34m(dataset, model, penalty, opt_scheme, lr, rank, device, loss_path, model_path, total_path)\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mtmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m                 \u001b[0mleast_square\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpenalty\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdct\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtemp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrank\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m                 \u001b[0mtrn_rmse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrn_mae\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m                 \u001b[0mval_rmse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_mae\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-43-5cc5eeb5fb5f>\u001b[0m in \u001b[0;36mleast_square\u001b[0;34m(model, train, penalty, mode, dct, temp, rank, device)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mdct\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdct\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mdct1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtemp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mParallel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_jobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnum_cores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdelayed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow_wise\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrows\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdct1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrows\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdct1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1015\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1016\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1017\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1018\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1019\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    907\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    908\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 909\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    910\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    911\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    560\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[1;32m    561\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 562\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    563\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mLokyTimeoutError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    564\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/tensor/lib/python3.6/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    430\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mCancelledError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    431\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mFINISHED\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 432\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    433\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/tensor/lib/python3.6/concurrent/futures/_base.py\u001b[0m in \u001b[0;36m__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    382\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 384\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    385\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: ones(): argument 'size' must be tuple of ints, but found element of type dict at pos 1"
     ]
    }
   ],
   "source": [
    "als_train_model(dataset, model, penalty, opt_scheme, lr, rank, device,\n",
    "                    loss_path, model_path, total_path)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dct[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# processed_list = Parallel(n_jobs=num_cores)(delayed(myfunction)(i,parameters) for i in inputs)\n",
    "def least_square(model, train, penalty, mode, dct, temp, rank, device):\n",
    "    num_cores = multiprocessing.cpu_count()\n",
    "    dct = dct[mode]\n",
    "    dct1 = temp[mode]\n",
    "    Parallel(n_jobs = num_cores)(delayed(row_wise)(idx, rows, dct1, model, mode) for idx, rows in dct1.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def row_wise(idx, rows, dct, model, mode):\n",
    "    ttime = time.time()\n",
    "    with torch.no_grad():\n",
    "        nnz = dct[idx]\n",
    "        nnz_idxs = rows['idx']\n",
    "        nnz_vals = rows['val']\n",
    "\n",
    "        update = sub_function(nnz_idxs, nnz_vals, nnz, model, mode)\n",
    "\n",
    "        model.factors[mode][idx] = update\n",
    "    print(time.time()-ttime);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sub_function(nnz_idxs, nnz_vals, nnz, model, mode):\n",
    "    ones = torch.ones((nnz, rank)).to(device)\n",
    "    for i, item in enumerate(zip(nnz_idxs.T, model.factors)):\n",
    "        if i != mode:\n",
    "            index, factor = item\n",
    "            ones = ones * factor[torch.LongTensor(index).to(device), :]\n",
    "\n",
    "    mat_b = torch.bmm(ones.view(nnz, rank, 1), ones.view(nnz, 1, rank))\n",
    "    mat_b2 = torch.sum(mat_b, dim=0) + torch.eye(rank).to(device) * penalty\n",
    "\n",
    "    vect_c = ones * torch.FloatTensor(nnz_vals).view(-1, 1).to(device)\n",
    "    vect_c = torch.sum(vect_c, dim=0)\n",
    "\n",
    "    ttime4 = time.time()\n",
    "\n",
    "    update = torch.matmul(torch.inverse(mat_b2), vect_c)\n",
    "    update = torch.where(torch.abs(update) < 0.000001, torch.zeros_like(update), update)\n",
    "    \n",
    "    return update\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def least_square(model, train, penalty, mode, dct, temp, rank, device):\n",
    "    dct = dct[mode]\n",
    "    dct1 = temp[mode]\n",
    "    for idx, rows in dct1.items():\n",
    "        ttime = time.time()\n",
    "        with torch.no_grad():\n",
    "            nnz = dct[idx]\n",
    "            nnz_idxs = rows['idx']\n",
    "            nnz_vals = rows['val']\n",
    "            \n",
    "            print(nnz, nnz_idxs, nnz_vals)\n",
    "            \n",
    "            update = sub_function(nnz_idxs, nnz_vals, nnz, model)\n",
    "                \n",
    "            model.factors[mode][idx] = update\n",
    "        print(time.time()-ttime);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def least_square(model, train, penalty, mode, dct, temp, rank, device):\n",
    "\n",
    "    mode = 2\n",
    "    nnz_count = dct[mode]\n",
    "    idxn = len(nnz_count)\n",
    "    idx_list = []\n",
    "    val_list = []\n",
    "    indices = nnz_count.keys()\n",
    "    for idx, nnz in nnz_count.items():\n",
    "        with torch.no_grad():\n",
    "            nnz_entries = temp[temp[:, mode] == idx]\n",
    "            nnz_idxs = nnz_entries[:, :-1]\n",
    "            nnz_vals = nnz_entries[:, -1]\n",
    "            idx_list.append(nnz_idxs)\n",
    "            val_list.append(nnz_vals)\n",
    "\n",
    "\n",
    "\n",
    "    print(idx_list[0])\n",
    "    idx_list = np.array(idx_list)\n",
    "\n",
    "    idx_list = torch.Tensor(idx_list)\n",
    "    print(idx_list.shape)\n",
    "    ones = torch.ones((idxn, nnz, rank)).to(device)\n",
    "    for i, item in enumerate(zip(idx_list, model.factors)):\n",
    "        if i != mode:\n",
    "            index, factor = item\n",
    "            ones = ones * factor[torch.LongTensor(index).to(device), :]\n",
    "\n",
    "    mat_b = torch.bmm(ones.view(idxn, nnz, rank, 1), ones.view(idxn, nnz, 1, rank))\n",
    "    # mat_b = torch.sum(mat_b, dim=0)\n",
    "    # lambda = torch.stack(torch.eye(rank) * idxn).to(device)\n",
    "    # mat_b2 = mat_b + lambda * 0.01\n",
    "    #\n",
    "    # vect_c = ones * torch.FloatTensor(nnz_vals).view(-1, 1).to(device)\n",
    "    # vect_c = torch.sum(vect_c, dim=0)\n",
    "    #\n",
    "    # update = torch.matmul(torch.inverse(mat_b2), vect_c)\n",
    "    # update = torch.where(torch.abs(update) < 0.000001, torch.zeros_like(update), update)\n",
    "    # model.factors[mode][idx] = update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def als_train_model(dataset, model, penalty, opt_scheme, lr, rank, device,\n",
    "                    loss_path, model_path, total_path):\n",
    "\n",
    "    train, valid, test = dataset['train'], dataset['valid'], dataset['test']\n",
    "    nmode, tmode = dataset['nmode'], dataset['tmode']\n",
    "    window, count = dataset['window'], dataset['count']\n",
    "\n",
    "    head = 'Iters\\tTime\\tTrnRMSE\\tTrMAE\\tValRMSE\\tValMAE\\n'\n",
    "    with open(loss_path, 'w') as f:\n",
    "        f.write(head)\n",
    "\n",
    "    dct, temp = metadata(train)\n",
    "    if opt_scheme == 'als_adam':\n",
    "        opt = optim.Adam([list(model.parameters())[tmode]], lr = lr)\n",
    "    else:\n",
    "        opt = optim.SGD([list(model.parameters())[tmode]], lr=lr)\n",
    "\n",
    "    start_time = time.time()\n",
    "    old_rmse, inner_rmse, stop_iter, = 1e+5, 1e+5, 0\n",
    "    for n_iter in trange(1, 1000):\n",
    "        inner_num = 0\n",
    "        stop = True\n",
    "        for mode in range(1, nmode):\n",
    "            if mode != tmode:\n",
    "                least_square(model, train, penalty, mode, dct, temp, rank, device)\n",
    "                trn_rmse, trn_mae = evaluate(model, train)\n",
    "                val_rmse, val_mae = evaluate(model, valid)\n",
    "                print('Iter', n_iter, 'Mode', mode, 'Train', trn_rmse, 'Valid', val_rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import torch\n",
    "import torch.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "\n",
    "from tqdm import tqdm\n",
    "from tqdm import trange\n",
    "from tatd.tatd import *\n",
    "from tatd.utils import *\n",
    "from tatd.train import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def gradient(model, opt, train, penalty, tmode):\n",
    "\n",
    "    opt.zero_grad()\n",
    "    rec = model(train.indices())\n",
    "    loss = (rec - train.values()).pow(2).sum()\n",
    "    loss = loss + penalty * model.smooth_reg(tmode)\n",
    "    print(f\"Loss :{model.smooth_reg(tmode).data}, Penalty :{penalty}\")\n",
    "    loss.backward()\n",
    "    opt.step()\n",
    "\n",
    "    return loss\n",
    "\n",
    "def metadata(train):\n",
    "    indices = train.indices().cpu().numpy()\n",
    "    vals = train.values().cpu().numpy()\n",
    "    temp = np.vstack([indices, vals]).T\n",
    "\n",
    "    dct = {}\n",
    "    for mode, index in enumerate(indices):\n",
    "        dct[mode] = {}\n",
    "        unique, counts = np.unique(index, return_counts=True)\n",
    "        for a, b in zip(* [unique, counts]):\n",
    "            dct[mode][a] = b\n",
    "\n",
    "    return dct, temp\n",
    "\n",
    "# def least_square(model, train, penalty, mode, dct, temp, rank, device):\n",
    "\n",
    "#     mode = 2\n",
    "#     nnz_count = dct[mode]\n",
    "#     idxn = len(nnz_count)\n",
    "#     idx_list = []\n",
    "#     val_list = []\n",
    "#     indices = nnz_count.keys()\n",
    "#     for idx, nnz in nnz_count.items():\n",
    "#         with torch.no_grad():\n",
    "#             nnz_entries = temp[temp[:, mode] == idx]\n",
    "#             nnz_idxs = nnz_entries[:, :-1]\n",
    "#             nnz_vals = nnz_entries[:, -1]\n",
    "#             idx_list.append(nnz_idxs)\n",
    "#             val_list.append(nnz_vals)\n",
    "\n",
    "\n",
    "\n",
    "#     print(idx_list[0])\n",
    "#     idx_list = np.array(idx_list)\n",
    "\n",
    "#     idx_list = torch.Tensor(idx_list)\n",
    "#     print(idx_list.shape)\n",
    "#     ones = torch.ones((idxn, nnz, rank)).to(device)\n",
    "#     for i, item in enumerate(zip(idx_list, model.factors)):\n",
    "#         if i != mode:\n",
    "#             index, factor = item\n",
    "#             ones = ones * factor[torch.LongTensor(index).to(device), :]\n",
    "\n",
    "#     mat_b = torch.bmm(ones.view(idxn, nnz, rank, 1), ones.view(idxn, nnz, 1, rank))\n",
    "#     # mat_b = torch.sum(mat_b, dim=0)\n",
    "#     # lambda = torch.stack(torch.eye(rank) * idxn).to(device)\n",
    "#     # mat_b2 = mat_b + lambda * 0.01\n",
    "#     #\n",
    "#     # vect_c = ones * torch.FloatTensor(nnz_vals).view(-1, 1).to(device)\n",
    "#     # vect_c = torch.sum(vect_c, dim=0)\n",
    "#     #\n",
    "#     # update = torch.matmul(torch.inverse(mat_b2), vect_c)\n",
    "#     # update = torch.where(torch.abs(update) < 0.000001, torch.zeros_like(update), update)\n",
    "#     # model.factors[mode][idx] = update\n",
    "\n",
    "# def als_train_model(dataset, model, penalty, opt_scheme, lr, rank, device,\n",
    "#                     loss_path, model_path, total_path):\n",
    "\n",
    "#     train, valid, test = dataset['train'], dataset['valid'], dataset['test']\n",
    "#     nmode, tmode = dataset['nmode'], dataset['tmode']\n",
    "#     window, count = dataset['window'], dataset['count']\n",
    "\n",
    "#     head = 'Iters\\tTime\\tTrnRMSE\\tTrMAE\\tValRMSE\\tValMAE\\n'\n",
    "#     with open(loss_path, 'w') as f:\n",
    "#         f.write(head)\n",
    "\n",
    "#     dct, temp = metadata(train)\n",
    "#     if opt_scheme == 'als_adam':\n",
    "#         opt = optim.Adam([list(model.parameters())[tmode]], lr = lr)\n",
    "#     else:\n",
    "#         opt = optim.SGD([list(model.parameters())[tmode]], lr=lr)\n",
    "\n",
    "#     start_time = time.time()\n",
    "#     old_rmse, inner_rmse, stop_iter, = 1e+5, 1e+5, 0\n",
    "#     for n_iter in trange(1, 1000):\n",
    "#         inner_num = 0\n",
    "#         stop = True\n",
    "#         for mode in range(nmode):\n",
    "#             if mode != tmode:\n",
    "#                 least_square(model, train, penalty, mode, dct, temp, rank, device)\n",
    "#                 trn_rmse, trn_mae = evaluate(model, train)\n",
    "#                 val_rmse, val_mae = evaluate(model, valid)\n",
    "#                 print('Iter', n_iter, 'Mode', mode, 'Train', trn_rmse, 'Valid', val_rmse)\n",
    "#             else:\n",
    "#                 model.turn_on_grad(mode)\n",
    "#                 while(stop):\n",
    "#                     stop = gradient(model, opt, train, penalty, tmode)\n",
    "#                     trn_rmse, trn_mae = evaluate(model, train)\n",
    "#                     val_rmse, val_mae = evaluate(model, valid)\n",
    "#                     print('Iter', n_iter, 'Mode', mode, 'Train', trn_rmse, 'Valid', val_rmse)\n",
    "# #                    print(val_rmse, inner_rmse)\n",
    "# #                    if np.abs(val_rmse - inner_rmse) < 0.00001:\n",
    "# #                        break\n",
    "#                     if inner_num > 1:\n",
    "#                         stop = False\n",
    "#                     if val_rmse > inner_rmse:\n",
    "#                         # break\n",
    "#                         inner_num += 1\n",
    "#                     inner_rmse = val_rmse\n",
    "#                     if isNaN(trn_rmse):\n",
    "#                         print(\"Nan break\")\n",
    "#                         break\n",
    "#             trn_rmse, trn_mae = evaluate(model, train)\n",
    "#             val_rmse, val_mae = evaluate(model, valid)\n",
    "\n",
    "#         if val_rmse > old_rmse and n_iter >1:\n",
    "#             stop_iter += 1\n",
    "#         old_rmse = val_rmse\n",
    "\n",
    "#         with open(loss_path, 'a') as f:\n",
    "#             elapsed = time.time() - start_time\n",
    "#             f.write(f'{n_iter:5d}\\t{elapsed:.5f}\\t')\n",
    "#             f.write(f'{trn_rmse:.5f}\\t{trn_mae:.5f}\\t')\n",
    "#             f.write(f'{val_rmse:.5f}\\t{val_mae:.5f}\\n')\n",
    "#         if stop_iter == 1 or n_iter == 999:\n",
    "#             te_rmse, te_mae = evaluate(model, test)\n",
    "#             with open(total_path, 'a') as f1:\n",
    "#                 f1.write(f'{count:5d}\\t{n_iter:5d}\\t{elapsed:.3f}\\t{model.sparse}\\t')\n",
    "#                 f1.write(f'{model.factors[0].shape[1]:2d}\\t')\n",
    "#                 f1.write(f'{window:2d}\\t{penalty:.3f}\\t')\n",
    "#                 f1.write(f'{opt_scheme}\\t{lr:5f}\\t')\n",
    "#                 f1.write(f'{te_rmse:.5f}\\t{te_mae:.5f}\\n')\n",
    "\n",
    "#             p = f'{model_path}-{n_iter}.pth.tar'\n",
    "#             save_checkpoints(model, p)\n",
    "#             break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
