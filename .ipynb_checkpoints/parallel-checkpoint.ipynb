{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7efc4381d1f0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from tatd.utils import *\n",
    "from tatd.read import *\n",
    "from tatd.tatd import *\n",
    "\n",
    "import argparse\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.manual_seed(1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "import torch.distributed as dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "from joblib import Parallel, delayed\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "name, sparse, rank, window, penalty, opt_scheme, lr, gpu, count = 'radar', 1, 10, 7, 0.1, 'als_adam', 0.01, 2, 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_path, model_path, total_path  = get_path(name, sparse, rank, window,  penalty,\n",
    "                                              opt_scheme, lr, count)\n",
    "device = f'cuda:{gpu}'\n",
    "\n",
    "dataset = read_dataset(name, device)\n",
    "dataset['count'], dataset['window'] = count, window\n",
    "nmode, ndim, tmode =  dataset['nmode'], dataset['ndim'], dataset['tmode']\n",
    "\n",
    "density = dataset['ts_beta']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "START radar sparse : True & als_adam : 0.01 Rank : 10 Window : 7 Penalty : 0.1 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = Tatd(nmode, ndim, tmode, density, rank, window, sparse, device).to(device)\n",
    "\n",
    "print(f\"START {name} sparse : {bool(sparse)} & {opt_scheme} : {lr} \"\n",
    "      f\"Rank : {rank} Window : {window} Penalty : {penalty} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metadata(train):\n",
    "    indices = train.indices().cpu().numpy()\n",
    "    vals = train.values().cpu().numpy()\n",
    "    temp = np.vstack([indices, vals]).T\n",
    "\n",
    "    dct = {}\n",
    "    dct1 = {}\n",
    "\n",
    "    for mode, index in enumerate(indices):\n",
    "        old_c = 0\n",
    "        dct[mode] = {}\n",
    "        dct1[mode] = {}\n",
    "        unique, indices, counts = np.unique(index, return_index = True, return_counts=True)\n",
    "        for a, c, b in zip(* [unique, indices[1:], counts]):\n",
    "            dct[mode][a] = b\n",
    "            dct1[mode][a] = {}\n",
    "            dct1[mode][a]['idx'] = {}\n",
    "            dct1[mode][a]['value'] = {}\n",
    "            nnz_entries = temp[old_c:c]\n",
    "            old_c = c\n",
    "            nnz_idxs = nnz_entries[:, :-1]\n",
    "            nnz_vals = nnz_entries[:, -1]\n",
    "            dct1[mode][a]['idx'] = nnz_idxs\n",
    "            dct1[mode][a]['val'] = nnz_vals\n",
    "\n",
    "    return dct, dct1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, valid, test = dataset['train'], dataset['valid'], dataset['test']\n",
    "nmode, tmode = dataset['nmode'], dataset['tmode']\n",
    "window, count = dataset['window'], dataset['count']\n",
    "\n",
    "dct, temp = metadata(train)\n",
    "opt = optim.Adam([list(model.parameters())[tmode]], lr = lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "num_cores = multiprocessing.cpu_count()\n",
    "# processed_list = Parallel(n_jobs=num_cores)(delayed(myfunction)(i,parameters) for i in inputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-95-0d706e1902c0>, line 11)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-95-0d706e1902c0>\"\u001b[0;36m, line \u001b[0;32m11\u001b[0m\n\u001b[0;31m    update = sub_function(nnz_idxs, nnz_vals, nnz, model):\u001b[0m\n\u001b[0m                                                         ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "def least_square(model, train, penalty, mode, dct, temp, rank, device):\n",
    "    dct = dct[mode]\n",
    "    dct1 = temp[mode]\n",
    "    for idx, rows in dct1.items():\n",
    "        ttime = time.time()\n",
    "        with torch.no_grad():\n",
    "            nnz = dct[idx]\n",
    "            nnz_idxs = rows['idx']\n",
    "            nnz_vals = rows['val']\n",
    "            \n",
    "            update = sub_function(nnz_idxs, nnz_vals, nnz, model):\n",
    "                \n",
    "            model.factors[mode][idx] = update\n",
    "        print(time.time()-ttime);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sub_function(nnz_idxs, nnz_vals, nnz, model):\n",
    "    ones = torch.cuda.ones((nnz, rank)).to(device)\n",
    "    for i, item in enumerate(zip(nnz_idxs.T, model.factors)):\n",
    "        if i != mode:\n",
    "            index, factor = item\n",
    "            ones = ones * factor[torch.LongTensor(index).to(device), :]\n",
    "\n",
    "    mat_b = torch.bmm(ones.view(nnz, rank, 1), ones.view(nnz, 1, rank))\n",
    "    mat_b2 = torch.sum(mat_b, dim=0) + torch.eye(rank).to(device) * penalty\n",
    "\n",
    "    vect_c = ones * torch.FloatTensor(nnz_vals).view(-1, 1).to(device)\n",
    "    vect_c = torch.sum(vect_c, dim=0)\n",
    "\n",
    "    ttime4 = time.time()\n",
    "\n",
    "    update = torch.matmul(torch.inverse(mat_b2), vect_c)\n",
    "    update = torch.where(torch.abs(update) < 0.000001, torch.zeros_like(update), update)\n",
    "    \n",
    "    return update\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def least_square(model, train, penalty, mode, dct, temp, rank, device):\n",
    "\n",
    "    mode = 2\n",
    "    nnz_count = dct[mode]\n",
    "    idxn = len(nnz_count)\n",
    "    idx_list = []\n",
    "    val_list = []\n",
    "    indices = nnz_count.keys()\n",
    "    for idx, nnz in nnz_count.items():\n",
    "        with torch.no_grad():\n",
    "            nnz_entries = temp[temp[:, mode] == idx]\n",
    "            nnz_idxs = nnz_entries[:, :-1]\n",
    "            nnz_vals = nnz_entries[:, -1]\n",
    "            idx_list.append(nnz_idxs)\n",
    "            val_list.append(nnz_vals)\n",
    "\n",
    "\n",
    "\n",
    "    print(idx_list[0])\n",
    "    idx_list = np.array(idx_list)\n",
    "\n",
    "    idx_list = torch.Tensor(idx_list)\n",
    "    print(idx_list.shape)\n",
    "    ones = torch.ones((idxn, nnz, rank)).to(device)\n",
    "    for i, item in enumerate(zip(idx_list, model.factors)):\n",
    "        if i != mode:\n",
    "            index, factor = item\n",
    "            ones = ones * factor[torch.LongTensor(index).to(device), :]\n",
    "\n",
    "    mat_b = torch.bmm(ones.view(idxn, nnz, rank, 1), ones.view(idxn, nnz, 1, rank))\n",
    "    # mat_b = torch.sum(mat_b, dim=0)\n",
    "    # lambda = torch.stack(torch.eye(rank) * idxn).to(device)\n",
    "    # mat_b2 = mat_b + lambda * 0.01\n",
    "    #\n",
    "    # vect_c = ones * torch.FloatTensor(nnz_vals).view(-1, 1).to(device)\n",
    "    # vect_c = torch.sum(vect_c, dim=0)\n",
    "    #\n",
    "    # update = torch.matmul(torch.inverse(mat_b2), vect_c)\n",
    "    # update = torch.where(torch.abs(update) < 0.000001, torch.zeros_like(update), update)\n",
    "    # model.factors[mode][idx] = update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def als_train_model(dataset, model, penalty, opt_scheme, lr, rank, device,\n",
    "                    loss_path, model_path, total_path):\n",
    "\n",
    "    train, valid, test = dataset['train'], dataset['valid'], dataset['test']\n",
    "    nmode, tmode = dataset['nmode'], dataset['tmode']\n",
    "    window, count = dataset['window'], dataset['count']\n",
    "\n",
    "    head = 'Iters\\tTime\\tTrnRMSE\\tTrMAE\\tValRMSE\\tValMAE\\n'\n",
    "    with open(loss_path, 'w') as f:\n",
    "        f.write(head)\n",
    "\n",
    "    dct, temp = metadata(train)\n",
    "    if opt_scheme == 'als_adam':\n",
    "        opt = optim.Adam([list(model.parameters())[tmode]], lr = lr)\n",
    "    else:\n",
    "        opt = optim.SGD([list(model.parameters())[tmode]], lr=lr)\n",
    "\n",
    "    start_time = time.time()\n",
    "    old_rmse, inner_rmse, stop_iter, = 1e+5, 1e+5, 0\n",
    "    for n_iter in trange(1, 1000):\n",
    "        inner_num = 0\n",
    "        stop = True\n",
    "        for mode in range(nmode):\n",
    "            if mode != tmode:\n",
    "                least_square(model, train, penalty, mode, dct, temp, rank, device)\n",
    "                trn_rmse, trn_mae = evaluate(model, train)\n",
    "                val_rmse, val_mae = evaluate(model, valid)\n",
    "                print('Iter', n_iter, 'Mode', mode, 'Train', trn_rmse, 'Valid', val_rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import torch\n",
    "import torch.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "\n",
    "from tqdm import tqdm\n",
    "from tqdm import trange\n",
    "from tatd.tatd import *\n",
    "from tatd.utils import *\n",
    "from tatd.train import *\n",
    "\n",
    "def gradient(model, opt, train, penalty, tmode):\n",
    "\n",
    "    opt.zero_grad()\n",
    "    rec = model(train.indices())\n",
    "    loss = (rec - train.values()).pow(2).sum()\n",
    "    loss = loss + penalty * model.smooth_reg(tmode)\n",
    "    print(f\"Loss :{model.smooth_reg(tmode).data}, Penalty :{penalty}\")\n",
    "    loss.backward()\n",
    "    opt.step()\n",
    "\n",
    "    return loss\n",
    "\n",
    "def metadata(train):\n",
    "    indices = train.indices().cpu().numpy()\n",
    "    vals = train.values().cpu().numpy()\n",
    "    temp = np.vstack([indices, vals]).T\n",
    "\n",
    "    dct = {}\n",
    "    for mode, index in enumerate(indices):\n",
    "        dct[mode] = {}\n",
    "        unique, counts = np.unique(index, return_counts=True)\n",
    "        for a, b in zip(* [unique, counts]):\n",
    "            dct[mode][a] = b\n",
    "\n",
    "    return dct, temp\n",
    "\n",
    "# def least_square(model, train, penalty, mode, dct, temp, rank, device):\n",
    "\n",
    "#     mode = 2\n",
    "#     nnz_count = dct[mode]\n",
    "#     idxn = len(nnz_count)\n",
    "#     idx_list = []\n",
    "#     val_list = []\n",
    "#     indices = nnz_count.keys()\n",
    "#     for idx, nnz in nnz_count.items():\n",
    "#         with torch.no_grad():\n",
    "#             nnz_entries = temp[temp[:, mode] == idx]\n",
    "#             nnz_idxs = nnz_entries[:, :-1]\n",
    "#             nnz_vals = nnz_entries[:, -1]\n",
    "#             idx_list.append(nnz_idxs)\n",
    "#             val_list.append(nnz_vals)\n",
    "\n",
    "\n",
    "\n",
    "#     print(idx_list[0])\n",
    "#     idx_list = np.array(idx_list)\n",
    "\n",
    "#     idx_list = torch.Tensor(idx_list)\n",
    "#     print(idx_list.shape)\n",
    "#     ones = torch.ones((idxn, nnz, rank)).to(device)\n",
    "#     for i, item in enumerate(zip(idx_list, model.factors)):\n",
    "#         if i != mode:\n",
    "#             index, factor = item\n",
    "#             ones = ones * factor[torch.LongTensor(index).to(device), :]\n",
    "\n",
    "#     mat_b = torch.bmm(ones.view(idxn, nnz, rank, 1), ones.view(idxn, nnz, 1, rank))\n",
    "#     # mat_b = torch.sum(mat_b, dim=0)\n",
    "#     # lambda = torch.stack(torch.eye(rank) * idxn).to(device)\n",
    "#     # mat_b2 = mat_b + lambda * 0.01\n",
    "#     #\n",
    "#     # vect_c = ones * torch.FloatTensor(nnz_vals).view(-1, 1).to(device)\n",
    "#     # vect_c = torch.sum(vect_c, dim=0)\n",
    "#     #\n",
    "#     # update = torch.matmul(torch.inverse(mat_b2), vect_c)\n",
    "#     # update = torch.where(torch.abs(update) < 0.000001, torch.zeros_like(update), update)\n",
    "#     # model.factors[mode][idx] = update\n",
    "\n",
    "# def als_train_model(dataset, model, penalty, opt_scheme, lr, rank, device,\n",
    "#                     loss_path, model_path, total_path):\n",
    "\n",
    "#     train, valid, test = dataset['train'], dataset['valid'], dataset['test']\n",
    "#     nmode, tmode = dataset['nmode'], dataset['tmode']\n",
    "#     window, count = dataset['window'], dataset['count']\n",
    "\n",
    "#     head = 'Iters\\tTime\\tTrnRMSE\\tTrMAE\\tValRMSE\\tValMAE\\n'\n",
    "#     with open(loss_path, 'w') as f:\n",
    "#         f.write(head)\n",
    "\n",
    "#     dct, temp = metadata(train)\n",
    "#     if opt_scheme == 'als_adam':\n",
    "#         opt = optim.Adam([list(model.parameters())[tmode]], lr = lr)\n",
    "#     else:\n",
    "#         opt = optim.SGD([list(model.parameters())[tmode]], lr=lr)\n",
    "\n",
    "#     start_time = time.time()\n",
    "#     old_rmse, inner_rmse, stop_iter, = 1e+5, 1e+5, 0\n",
    "#     for n_iter in trange(1, 1000):\n",
    "#         inner_num = 0\n",
    "#         stop = True\n",
    "#         for mode in range(nmode):\n",
    "#             if mode != tmode:\n",
    "#                 least_square(model, train, penalty, mode, dct, temp, rank, device)\n",
    "#                 trn_rmse, trn_mae = evaluate(model, train)\n",
    "#                 val_rmse, val_mae = evaluate(model, valid)\n",
    "#                 print('Iter', n_iter, 'Mode', mode, 'Train', trn_rmse, 'Valid', val_rmse)\n",
    "#             else:\n",
    "#                 model.turn_on_grad(mode)\n",
    "#                 while(stop):\n",
    "#                     stop = gradient(model, opt, train, penalty, tmode)\n",
    "#                     trn_rmse, trn_mae = evaluate(model, train)\n",
    "#                     val_rmse, val_mae = evaluate(model, valid)\n",
    "#                     print('Iter', n_iter, 'Mode', mode, 'Train', trn_rmse, 'Valid', val_rmse)\n",
    "# #                    print(val_rmse, inner_rmse)\n",
    "# #                    if np.abs(val_rmse - inner_rmse) < 0.00001:\n",
    "# #                        break\n",
    "#                     if inner_num > 1:\n",
    "#                         stop = False\n",
    "#                     if val_rmse > inner_rmse:\n",
    "#                         # break\n",
    "#                         inner_num += 1\n",
    "#                     inner_rmse = val_rmse\n",
    "#                     if isNaN(trn_rmse):\n",
    "#                         print(\"Nan break\")\n",
    "#                         break\n",
    "#             trn_rmse, trn_mae = evaluate(model, train)\n",
    "#             val_rmse, val_mae = evaluate(model, valid)\n",
    "\n",
    "#         if val_rmse > old_rmse and n_iter >1:\n",
    "#             stop_iter += 1\n",
    "#         old_rmse = val_rmse\n",
    "\n",
    "#         with open(loss_path, 'a') as f:\n",
    "#             elapsed = time.time() - start_time\n",
    "#             f.write(f'{n_iter:5d}\\t{elapsed:.5f}\\t')\n",
    "#             f.write(f'{trn_rmse:.5f}\\t{trn_mae:.5f}\\t')\n",
    "#             f.write(f'{val_rmse:.5f}\\t{val_mae:.5f}\\n')\n",
    "#         if stop_iter == 1 or n_iter == 999:\n",
    "#             te_rmse, te_mae = evaluate(model, test)\n",
    "#             with open(total_path, 'a') as f1:\n",
    "#                 f1.write(f'{count:5d}\\t{n_iter:5d}\\t{elapsed:.3f}\\t{model.sparse}\\t')\n",
    "#                 f1.write(f'{model.factors[0].shape[1]:2d}\\t')\n",
    "#                 f1.write(f'{window:2d}\\t{penalty:.3f}\\t')\n",
    "#                 f1.write(f'{opt_scheme}\\t{lr:5f}\\t')\n",
    "#                 f1.write(f'{te_rmse:.5f}\\t{te_mae:.5f}\\n')\n",
    "\n",
    "#             p = f'{model_path}-{n_iter}.pth.tar'\n",
    "#             save_checkpoints(model, p)\n",
    "#             break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
